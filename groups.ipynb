{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "import statistics\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import scipy.stats as sps\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "survey_files=[\"./survey_fcasts.yr1.csv\"]\n",
    "#, \"./survey_fcasts.yr2.csv\", \"./survey_fcasts.yr3.csv\", \"./survey_fcasts.yr4.csv\"]\n",
    "\n",
    "MIN_PROB=0.01\n",
    "EXTR=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of individual forecasts. Type: List of dictionaries.\n",
    "# Fields:\n",
    "# {'ifp_id', 'ctt', 'cond', 'training', 'team', 'user_id', 'forecast_id', 'fcast_type', 'answer_option', 'value', 'fcast_date', 'expertise', 'q_status', 'viewtime', 'year', 'timestamp'}\n",
    "\n",
    "preds=[]\n",
    "\n",
    "year=1\n",
    "\n",
    "for n in survey_files:\n",
    "    f=open(n)\n",
    "    forecast_reader=csv.DictReader(f)\n",
    "    for entry in forecast_reader:\n",
    "        entry['year']=year\n",
    "        entry['cond']=int(entry['cond'])\n",
    "        entry['value']=float(entry['value'])\n",
    "        entry['timestamp']=dt.fromisoformat(entry['timestamp'])\n",
    "        preds.append(entry)\n",
    "    year=year+1\n",
    "\n",
    "# List of individual questions. Type: List of dictionaries.\n",
    "# Fields:\n",
    "# {'ifp_id', 'q_type', 'q_text', 'q_desc', 'q_status', 'date_start', 'date_suspend', 'date_to_close', 'date_closed', 'outcome', 'short_title', 'days_open', 'n_opts', 'options'}\n",
    "\n",
    "qdata=[]\n",
    "\n",
    "qfile=open(\"ifps.csv\")\n",
    "qreader=csv.DictReader(qfile)\n",
    "\n",
    "for entry in qreader:\n",
    "    if entry['date_start']!='NULL':\n",
    "        entry['date_start']=dt.strptime(entry['date_start'], '%m/%d/%y')\n",
    "    if entry['date_suspend']!='NULL':\n",
    "        entry['date_suspend']=dt.strptime(entry['date_suspend'], '%m/%d/%y %H:%M')\n",
    "    qdata.append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem with the code below: The Brier score has two different formulations (one equivalent to the mean squared error, another one being the original formulation by Brier). Only the original formulation is proper for forecasts on >2 options.\n",
    "\n",
    "TODO: implement the original formulation: $BS=\\frac{1}{N} \\sum_{t=1}^{N} \\sum_{i=1}^R (f_{ti}-o_{ti})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_score(user_forecasts, users):\n",
    "    forecasts=np.array([])\n",
    "    results=np.array([])\n",
    "    for u in users:\n",
    "        udata=user_forecasts[u]\n",
    "        forecasts=np.append(forecasts, np.array(udata['forecasts']))\n",
    "        results=np.append(results, np.array(udata['options'])==np.array(udata['outcomes']))\n",
    "    return np.mean((forecasts-results)**2)\n",
    "\n",
    "def individual_score(user):\n",
    "    return np.mean((np.array(user['forecasts'])-(np.array(user['options'])==np.array(user['outcomes'])))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different structures of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcomes of questions.\n",
    "# Type: Dictionary.\n",
    "# Fields: Keys are question ids (`ifp_id`), values are dictionaries (fields are `outcome`, `date_start`, `date_suspend`)\n",
    "\n",
    "questions=dict()\n",
    "\n",
    "for q in qdata:\n",
    "    qid=q['ifp_id']\n",
    "    if not qid in questions:\n",
    "        questions[qid]=dict()\n",
    "    questions[qid]['outcome']=q['outcome']\n",
    "    questions[qid]['date_start']=q['date_start']\n",
    "    questions[qid]['date_suspend']=q['date_suspend']\n",
    "    questions[qid]['q_status']=q['q_status']\n",
    "\n",
    "for p in preds:\n",
    "    p['outcome']=questions[p['ifp_id']]['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All forecasts, per user.\n",
    "# Type: Dictionary of dictionaries. (\"Look on my works, ye Mighty, and despair!\")\n",
    "# Fields: Keys are user ids (`user_id`), values are dictionaries, where:\n",
    "# keys are 'forecasts', 'options' and 'outcomes'.\n",
    "\n",
    "user_forecasts=dict()\n",
    "\n",
    "for p in preds:\n",
    "    uid=p['user_id']\n",
    "    if not user_forecasts.__contains__(uid):\n",
    "        user_forecasts[uid]=dict()\n",
    "        user_forecasts[uid]['forecasts']=[]\n",
    "        user_forecasts[uid]['options']=[]\n",
    "        user_forecasts[uid]['outcomes']=[]\n",
    "    user_forecasts[uid]['forecasts'].append(p['value'])\n",
    "    user_forecasts[uid]['options'].append(p['answer_option'])\n",
    "    user_forecasts[uid]['outcomes'].append(p['outcome'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the file survey_fcasts.yr1.csv there are a couple of forecasts made by the user \"NULL\"\n",
    "# I don't know what this means: I suspected at first that those were forecasts on \"voided\" questions,\n",
    "# but it turns out that that's not the case.\n",
    "# To be sure, I'll delete the forecasts by that user from the data.\n",
    "\n",
    "if 'NULL' in user_forecasts.keys():\n",
    "    user_forecasts.pop('NULL')\n",
    "users=list(user_forecasts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorted list of all scores individuals have received.\n",
    "# Type: List of floats.\n",
    "\n",
    "individual_scores=np.array([])\n",
    "\n",
    "for k in user_forecasts.keys():\n",
    "    u=user_forecasts[k]\n",
    "    u['brier']=individual_score(u)\n",
    "    individual_scores=np.append(individual_scores, u['brier'])\n",
    "\n",
    "individual_scores=np.sort(individual_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which teams to associate to each forecaster.\n",
    "# Type: Dictionary.\n",
    "# Fields: Keys are user ids (`user_id`), values are sets of team ids (`team`), usually (but not always!) unique.\n",
    "\n",
    "user_teams=dict()\n",
    "\n",
    "for p in preds:\n",
    "    uid=p['user_id']\n",
    "    if not user_teams.__contains__(uid):\n",
    "        user_teams[uid]=dict()\n",
    "        user_teams[uid]['teams']=set()\n",
    "    user_teams[uid]['teams']\n",
    "    if not p['team'] in user_teams[uid]['teams']:\n",
    "        user_teams[uid]['teams'].add(p['team'])\n",
    "\n",
    "for k in user_teams:\n",
    "    if len(user_teams[k]['teams'])!=1:\n",
    "        print(k, user_teams[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each question, which forecaster made which prediction when?\n",
    "# Type: dictionary of dictionaries of dictionaries (!) of lists\n",
    "# Fields: Keys are question ids (`ifp_id`), values are dictionaries\n",
    "# where keys are `forecasters`, `outcome`, `date_start` or\n",
    "# `date_suspend`, `forecasters` is a dictionary where the keys are\n",
    "# user ids (`user_id`) and values are dictionaries, where keys are\n",
    "# `forecasts`, `options`, `timestamps` (all numpy lists).\n",
    "\n",
    "q_fsters=dict()\n",
    "\n",
    "# collect the data\n",
    "\n",
    "for p in preds:\n",
    "    qid=p['ifp_id']\n",
    "    if not qid in q_fsters:\n",
    "        q_fsters[qid]=dict()\n",
    "        q_fsters[qid]['outcome']=questions[qid]['outcome']\n",
    "        q_fsters[qid]['date_start']=questions[qid]['date_start']\n",
    "        q_fsters[qid]['date_suspend']=questions[qid]['date_suspend']\n",
    "        q_fsters[qid]['q_status']=questions[qid]['q_status']\n",
    "        q_fsters[qid]['forecasters']=dict()\n",
    "    uid=p['user_id']\n",
    "    if not uid in q_fsters[qid]['forecasters']:\n",
    "        q_fsters[qid]['forecasters'][uid]=dict()\n",
    "        q_fsters[qid]['forecasters'][uid]['forecasts']=[]\n",
    "        q_fsters[qid]['forecasters'][uid]['options']=[]\n",
    "        q_fsters[qid]['forecasters'][uid]['timestamps']=[]\n",
    "    q_fsters[qid]['forecasters'][uid]['forecasts'].append(p['value'])\n",
    "    q_fsters[qid]['forecasters'][uid]['options'].append(p['answer_option'])\n",
    "    q_fsters[qid]['forecasters'][uid]['timestamps'].append(p['timestamp'])\n",
    "\n",
    "# sort the data\n",
    "\n",
    "for qid in q_fsters.keys():\n",
    "    for uid in q_fsters[qid]['forecasters'].keys():\n",
    "        q_fsters[qid]['forecasters'][uid]['timestamps']=np.array(q_fsters[qid]['forecasters'][uid]['timestamps'])\n",
    "        indices=np.argsort(q_fsters[qid]['forecasters'][uid]['timestamps'])\n",
    "        q_fsters[qid]['forecasters'][uid]['timestamps']=q_fsters[qid]['forecasters'][uid]['timestamps'][indices]\n",
    "        q_fsters[qid]['forecasters'][uid]['forecasts']=np.array(q_fsters[qid]['forecasters'][uid]['forecasts'])[indices]\n",
    "        q_fsters[qid]['forecasters'][uid]['options']=np.array(q_fsters[qid]['forecasters'][uid]['options'])[indices]\n",
    "\n",
    "        # replacing forecasts with probability 0 with forecasts with probability 0.01\n",
    "        q_fsters[qid]['forecasters'][uid]['forecasts'][np.where(q_fsters[qid]['forecasters'][uid]['forecasts']==0)]=MIN_PROB\n",
    "        q_fsters[qid]['forecasters'][uid]['forecasts'][np.where(q_fsters[qid]['forecasters'][uid]['forecasts']==1)]=1-MIN_PROB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forecasts per question\n",
    "\n",
    "q_forecasts=dict()\n",
    "\n",
    "for qid in q_fsters.keys():\n",
    "    q_forecasts[qid]=dict()\n",
    "    for uid in q_fsters[qid]['forecasters'].keys():\n",
    "        for i in range(0, len(q_fsters[qid]['forecasters'][uid]['options'])-1):\n",
    "            opt=q_fsters[qid]['forecasters'][uid]['options'][i]\n",
    "            if not opt in q_forecasts[qid]:\n",
    "                q_forecasts[qid][opt]=dict()\n",
    "                q_forecasts[qid][opt]['forecasts']=[]\n",
    "                q_forecasts[qid][opt]['timestamps']=[]\n",
    "            q_forecasts[qid][opt]['forecasts'].append(q_fsters[qid]['forecasters'][uid]['forecasts'][i])\n",
    "            q_forecasts[qid][opt]['timestamps'].append(q_fsters[qid]['forecasters'][uid]['timestamps'][i])\n",
    "\n",
    "for qid in q_forecasts.keys():\n",
    "    for o in q_forecasts[qid].keys():\n",
    "        q_forecasts[qid][o]['forecasts']=np.array(q_forecasts[qid][o]['forecasts'])\n",
    "        q_forecasts[qid][o]['timestamps']=np.array(q_forecasts[qid][o]['timestamps'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['arith', 'probs', 'nodec', 'gjpextr'], ['arith', 'probs', 'nodec', 'postextr'], ['arith', 'probs', 'nodec', 'neyextr'], ['arith', 'probs', 'nodec', 'noextr'], ['arith', 'odds', 'nodec', 'gjpextr'], ['arith', 'odds', 'nodec', 'postextr'], ['arith', 'odds', 'nodec', 'neyextr'], ['arith', 'odds', 'nodec', 'noextr'], ['geom', 'probs', 'nodec', 'gjpextr'], ['geom', 'probs', 'nodec', 'postextr'], ['geom', 'probs', 'nodec', 'neyextr'], ['geom', 'probs', 'nodec', 'noextr'], ['geom', 'odds', 'nodec', 'gjpextr'], ['geom', 'odds', 'nodec', 'postextr'], ['geom', 'odds', 'nodec', 'neyextr'], ['geom', 'odds', 'nodec', 'noextr'], ['median', 'probs', 'nodec', 'gjpextr'], ['median', 'probs', 'nodec', 'postextr'], ['median', 'probs', 'nodec', 'neyextr'], ['median', 'probs', 'nodec', 'noextr'], ['median', 'odds', 'nodec', 'gjpextr'], ['median', 'odds', 'nodec', 'postextr'], ['median', 'odds', 'nodec', 'neyextr'], ['median', 'odds', 'nodec', 'noextr'], ['median', 'logodds', 'nodec', 'gjpextr'], ['median', 'logodds', 'nodec', 'postextr'], ['median', 'logodds', 'nodec', 'neyextr'], ['median', 'logodds', 'nodec', 'noextr']]\n"
     ]
    }
   ],
   "source": [
    "# aggregations methods\n",
    "\n",
    "aggregations=dict()\n",
    "\n",
    "# different per-question aggregation methods\n",
    "# {arithmetic mean, geometric mean, median}×{probs, odds, log odds}×{exponential decay, no decay}×{extremized, not extremized}\n",
    "means=['arith', 'geom', 'median']\n",
    "formats=['probs', 'odds', 'logodds']\n",
    "decay=['nodec']#, 'nodec']\n",
    "extremize=['gjpextr', 'postextr', 'neyextr', 'noextr']\n",
    "\n",
    "aggr_methods=[]\n",
    "\n",
    "for i1 in means:\n",
    "    for i2 in formats:\n",
    "        for i3 in decay:\n",
    "            for i4 in extremize:\n",
    "                #the first sometimes doesn't work (negative values), the second is equivalent to the geometric mean of odds\n",
    "                if (i1=='geom' and i2=='logodds') or (i1=='arith' and i2=='logodds'):\n",
    "                    continue\n",
    "                aggr_methods.append([i1, i2, i3, i4])\n",
    "\n",
    "print(aggr_methods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# differently aggregated means\n",
    "\n",
    "for a in aggr_methods:\n",
    "    aggrkey='_'.join(a)\n",
    "    aggregations[aggrkey]=dict()\n",
    "    for qid in q_forecasts.keys():\n",
    "        aggregations[aggrkey][qid]=dict()\n",
    "        aggregations[aggrkey][qid]['outcome']=questions[qid]['outcome']\n",
    "        aggregations[aggrkey][qid]['aggr_forecasts']=[]\n",
    "        aggregations[aggrkey][qid]['options']=[]\n",
    "\n",
    "        for o in q_forecasts[qid].keys():\n",
    "            n=len(q_forecasts[qid][o]['forecasts'])\n",
    "            if 'probs' in a:\n",
    "                poss_transformed=q_forecasts[qid][o]['forecasts']\n",
    "            elif 'odds' in a:\n",
    "                poss_transformed=q_forecasts[qid][o]['forecasts']/(1-q_forecasts[qid][o]['forecasts'])\n",
    "            elif 'logodds' in a:\n",
    "                poss_transformed=q_forecasts[qid][o]['forecasts']/(1-q_forecasts[qid][o]['forecasts'])\n",
    "                poss_transformed=np.log(poss_transformed)\n",
    "\n",
    "            if 'arith' in a:\n",
    "                aggregations[aggrkey][qid]['aggr_forecasts'].append(np.mean(poss_transformed))\n",
    "            elif 'geom' in a:\n",
    "                aggregations[aggrkey][qid]['aggr_forecasts'].append(statistics.geometric_mean(poss_transformed))\n",
    "            elif 'median' in a:\n",
    "                aggregations[aggrkey][qid]['aggr_forecasts'].append(np.median(poss_transformed))\n",
    "\n",
    "            aggregations[aggrkey][qid]['options'].append(o)\n",
    "\n",
    "        if 'odds' in a:\n",
    "            odds=np.array(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "            aggregations[aggrkey][qid]['aggr_forecasts']=odds/(1+odds)\n",
    "        elif 'logodds' in a:\n",
    "            log_odds=np.array(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "            odds=np.exp(log_odds)\n",
    "            aggregations[aggrkey][qid]['aggr_forecasts']=odds/(1+odds)\n",
    "\n",
    "        if 'gjpextr' in a:\n",
    "            p=np.array(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "            aggregations[aggrkey][qid]['aggr_forecasts']=((p**EXTR)/(((p**EXTR)+(1-p))**(1/EXTR)))\n",
    "        elif 'postextr' in a:\n",
    "            p=np.array(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "            aggregations[aggrkey][qid]['aggr_forecasts']=p**EXTR\n",
    "        elif 'neyextr' in a:\n",
    "            p=np.array(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "            d=n*(math.sqrt(3*n**2-3*n+1)-2)/(n**2-n-1)\n",
    "            aggregations[aggrkey][qid]['aggr_forecasts']=p**d\n",
    "\n",
    "        aggregations[aggrkey][qid]['options']=np.array(aggregations[aggrkey][qid]['options'])\n",
    "        aggregations[aggrkey][qid]['aggr_forecasts']=np.array(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "\n",
    "        # Renormalize to 1\n",
    "        Z=np.sum(aggregations[aggrkey][qid]['aggr_forecasts'])\n",
    "        aggregations[aggrkey][qid]['aggr_forecasts']/=Z\n",
    "\n",
    "for a in aggregations.keys():\n",
    "    briers=[]\n",
    "    for qid in aggregations[a].keys():\n",
    "        aggregations[a][qid]['brier']=np.mean((aggregations[a][qid]['aggr_forecasts']-(aggregations[a][qid]['outcome']==aggregations[a][qid]['options']))**2)\n",
    "        briers.append(aggregations[a][qid]['brier'])\n",
    "    aggregations[a]['brier']=np.mean(np.array(briers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Peeking into the data structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forecast:  {'ifp_id': '1004-0', 'ctt': '1a', 'cond': 1, 'training': 'a', 'team': 'NA', 'user_id': '600', 'forecast_id': '-200987', 'fcast_type': '0', 'answer_option': 'a', 'value': 0.1, 'fcast_date': '2011-08-31', 'expertise': '1', 'q_status': 'closed', 'viewtime': 'NA', 'year': 1, 'timestamp': datetime.datetime(2011, 8, 31, 16, 17, 18), 'outcome': 'b'}\n",
      "question:  {'ifp_id': '1001-0', 'q_type': '0', 'q_text': 'Will the Six-Party talks (among the US, North Korea, South Korea, Russia, China, and Japan) formally resume in 2011?', 'q_desc': \"'In' refers to any time during the remainder of the 2011 calendar year, as defined by Eastern Time. Outcome will be resolved based on reporting from one or more of the following sources: BBC News or Reuters or Economist Online (http://www.bbc.co.uk/news/ or http://www.reuters.com/ or http://www.economist.com). If nothing is reported in these sources, then the 'status quo' outcome typically will be assumed (e.g., for a question about a political leader leaving office, an absence of reporting will be taken to indicate that the leader remains in office).  Administrator reserves the right to use other sources as needed (e.g., CIA World Factbook, Wikipedia), provided those sources do not directly contradict concurrent event reporting from BBC News, Reuters, or Economist Online. In cases of substantial controversy or uncertainty, Administrator may refer the question to outside subject matter experts, or we may deem the question invalid/void.\", 'q_status': 'closed', 'date_start': datetime.datetime(2011, 9, 1, 0, 0), 'date_suspend': datetime.datetime(2011, 12, 30, 0, 0), 'date_to_close': '12/31/11', 'date_closed': '1/2/12', 'outcome': 'b', 'short_title': 'Six-party talks resume', 'days_open': '123', 'n_opts': '2', 'options': '(a) Yes, (b) No'}\n",
      "question result:  {'outcome': 'b', 'date_start': datetime.datetime(2011, 9, 1, 0, 0), 'date_suspend': datetime.datetime(2011, 12, 30, 0, 0), 'q_status': 'closed'}\n",
      "all individual scores, sorted:  [0.000e+00 0.000e+00 3.750e-05 ... 6.400e-01 7.225e-01 8.100e-01]\n",
      "all teams for a user:  {'teams': {'8'}}\n"
     ]
    }
   ],
   "source": [
    "print(\"forecast: \", preds[0])\n",
    "print(\"question: \", qdata[0])\n",
    "print(\"question result: \", questions['1001-0'])\n",
    "print(\"all individual scores, sorted: \", individual_scores)\n",
    "print(\"all teams for a user: \", user_teams['3304'])\n",
    "#print(\"results for aggregation: \", aggregations)\n",
    "#print(\"user forecasts: \", user_forecasts['3304'])\n",
    "#print(\"data of questions, by forecasters: \", q_fsters['1176-0'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the advantage of different types of groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Of these, the most important and least obvious is the transformation of the aggregate forecasts. Note that we take the weighted mean first, and then transform;\n",
    "this works much better than transforming first and then averaging\n",
    "the transformed individual predictions. The transformation we used is: $\\frac{p^a}{(p^a+(1-p))^{\\frac{1}{a}}}$ with $a=3$.\n",
    "\n",
    "*— Lyle Ungar et al., “The Good Judgment Project: A large scale test of different methods of combining expert predictions” p. 2, 2012*\n",
    "\n",
    "TODO: check that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "geom_odds_nodec_postextr 0.06684331420597692\n",
      "geom_odds_nodec_gjpextr 0.06685036961388066\n",
      "geom_probs_nodec_postextr 0.06948618742701797\n",
      "geom_probs_nodec_gjpextr 0.06971932842735376\n",
      "arith_probs_nodec_gjpextr 0.07178242689262797\n",
      "arith_probs_nodec_postextr 0.07208091809301938\n",
      "geom_odds_nodec_neyextr 0.07231780719749753\n",
      "geom_probs_nodec_neyextr 0.07291391843827348\n",
      "median_logodds_nodec_postextr 0.0772573134290434\n",
      "median_probs_nodec_postextr 0.07725829634908649\n",
      "median_odds_nodec_postextr 0.07726297637880059\n",
      "median_logodds_nodec_gjpextr 0.07729252652831538\n",
      "median_probs_nodec_gjpextr 0.0772935031717426\n",
      "median_odds_nodec_gjpextr 0.07729827605332332\n",
      "median_logodds_nodec_neyextr 0.08259674842253747\n",
      "median_probs_nodec_neyextr 0.08259785089346433\n",
      "median_odds_nodec_neyextr 0.08260076153437045\n",
      "arith_probs_nodec_neyextr 0.08721705632596859\n",
      "geom_probs_nodec_noextr 0.09383628773950334\n",
      "geom_odds_nodec_noextr 0.09423579611898124\n",
      "median_logodds_nodec_noextr 0.10458883612613978\n",
      "median_probs_nodec_noextr 0.10458994722833861\n",
      "median_odds_nodec_noextr 0.10459145402895716\n",
      "arith_odds_nodec_postextr 0.10468066221010718\n",
      "arith_odds_nodec_gjpextr 0.10931696319876384\n",
      "arith_probs_nodec_noextr 0.1184986726497717\n",
      "arith_odds_nodec_neyextr 0.13669249765530317\n",
      "arith_odds_nodec_noextr 0.17069268089648382\n",
      "[0.000e+00 0.000e+00 3.750e-05 ... 6.400e-01 7.225e-01 8.100e-01]\n"
     ]
    }
   ],
   "source": [
    "l=[(aggregations[k]['brier'],k) for k in aggregations.keys()]\n",
    "l.sort()\n",
    "\n",
    "for e in l:\n",
    "    print(e[1], e[0])\n",
    "\n",
    "print(individual_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 0.47920892494929007\n",
      "3 0.49594320486815413\n",
      "4 0.48225152129817445\n",
      "5 0.4964503042596349\n",
      "6 0.4934077079107505\n",
      "7 0.49391480730223125\n",
      "8 0.505578093306288\n",
      "9 0.5106490872210954\n",
      "10 0.5\n",
      "11 0.5111561866125761\n",
      "12 0.5060851926977687\n",
      "13 0.513184584178499\n",
      "14 0.5086206896551724\n",
      "15 0.5152129817444219\n",
      "16 0.5025354969574036\n",
      "17 0.5081135902636917\n",
      "18 0.5060851926977687\n",
      "19 0.5157200811359026\n",
      "20 0.5136916835699797\n",
      "21 0.5121703853955375\n",
      "22 0.518762677484787\n",
      "23 0.5157200811359026\n",
      "24 0.518762677484787\n",
      "25 0.5162271805273834\n",
      "26 0.5126774847870182\n",
      "27 0.5152129817444219\n",
      "28 0.5157200811359026\n",
      "29 0.5202839756592292\n",
      "30 0.5177484787018256\n",
      "31 0.5101419878296146\n",
      "32 0.5182555780933062\n",
      "33 0.5212981744421906\n",
      "34 0.507606490872211\n",
      "35 0.5141987829614605\n",
      "36 0.5172413793103449\n",
      "37 0.5192697768762677\n",
      "38 0.5192697768762677\n",
      "39 0.5141987829614605\n",
      "40 0.5167342799188641\n",
      "41 0.52079107505071\n",
      "42 0.5141987829614605\n",
      "43 0.5157200811359026\n",
      "44 0.5147058823529411\n",
      "45 0.5157200811359026\n",
      "46 0.5157200811359026\n",
      "47 0.5162271805273834\n",
      "48 0.5192697768762677\n",
      "49 0.5197768762677485\n",
      "50 0.5157200811359026\n",
      "51 0.5202839756592292\n",
      "52 0.5202839756592292\n",
      "53 0.5162271805273834\n",
      "54 0.5177484787018256\n",
      "55 0.518762677484787\n",
      "56 0.5141987829614605\n",
      "57 0.5167342799188641\n",
      "58 0.5152129817444219\n",
      "59 0.5157200811359026\n",
      "60 0.5202839756592292\n",
      "61 0.5162271805273834\n",
      "62 0.52079107505071\n",
      "63 0.5212981744421906\n",
      "64 0.5212981744421906\n",
      "65 0.5177484787018256\n",
      "66 0.5157200811359026\n",
      "67 0.5182555780933062\n",
      "68 0.5197768762677485\n",
      "69 0.5177484787018256\n",
      "70 0.5212981744421906\n",
      "71 0.5202839756592292\n",
      "72 0.5202839756592292\n",
      "73 0.5212981744421906\n",
      "74 0.5162271805273834\n",
      "75 0.5157200811359026\n",
      "76 0.5197768762677485\n",
      "77 0.5197768762677485\n",
      "78 0.5157200811359026\n",
      "79 0.5182555780933062\n",
      "80 0.5162271805273834\n",
      "81 0.518762677484787\n",
      "82 0.5157200811359026\n",
      "83 0.5212981744421906\n",
      "84 0.5152129817444219\n",
      "85 0.5238336713995944\n",
      "86 0.5212981744421906\n",
      "87 0.5162271805273834\n",
      "88 0.5202839756592292\n",
      "89 0.5192697768762677\n",
      "90 0.5202839756592292\n",
      "91 0.5202839756592292\n",
      "92 0.5202839756592292\n",
      "93 0.5177484787018256\n",
      "94 0.5167342799188641\n",
      "95 0.5192697768762677\n",
      "96 0.5197768762677485\n",
      "97 0.5141987829614605\n",
      "98 0.5172413793103449\n",
      "99 0.5162271805273834\n",
      "100 0.5197768762677485\n"
     ]
    }
   ],
   "source": [
    "GROUP_SCORE_SAMPLES=500\n",
    "MAX_GROUP_SIZE=100\n",
    "\n",
    "group_scores=dict()\n",
    "\n",
    "for size in range(2, MAX_GROUP_SIZE+1):\n",
    "    samples=[]\n",
    "    for n in range(0, GROUP_SCORE_SAMPLES):\n",
    "        sample_group=random.sample(users, size)\n",
    "        score=group_score(user_forecasts, sample_group)\n",
    "        samples.append(score)\n",
    "    group_scores[size]=np.mean(np.array(samples))\n",
    "\n",
    "for k in group_scores.keys():\n",
    "    print(k, len((np.where(individual_scores>group_scores[k]))[0])/len(individual_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
